{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled12.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMV2EtgKR21O9CwjKxJ5n9z",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/KimJuHan/pytorch_tutorial/blob/master/kaggle_housePrice_prediction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OW901IRbcufh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 127
        },
        "outputId": "56330921-756b-4689-c08d-edbc2344e4de"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dHQhUNf6c1yH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "e248f99e-27ac-4443-a65e-a496f9ccf69a"
      },
      "source": [
        "cd /content/gdrive/My\\ Drive/data/house_price_regression"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/gdrive/My Drive/data/house_price_regression\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VWR_dJtPdYru",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "import torch\n",
        "from torch import nn, optim, cuda\n",
        "from torch.utils.data import Dataset,DataLoader\n",
        "import torch.nn.functional as F\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "%matplotlib inline"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SqrctuvGeH0c",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 557
        },
        "outputId": "b80c635f-2467-460a-8989-0587464e7698"
      },
      "source": [
        "train_data = pd.read_csv('./train.csv')\n",
        "test_data = pd.read_csv('./test.csv')\n",
        "print(train_data.shape)\n",
        "print(test_data.shape)\n",
        "# train data + test data\n",
        "data = train_data.append(test_data, ignore_index=True)\n",
        "# categorical variable => dummy variable\n",
        "# get_dummies() : series 객체와 dataFrame 객체를 인자로 받을 수 있음\n",
        "# dataFrame 객체를 인자로 받는 경우, numerical value를 갖는 칼럼은 더미값생성을 하지 않는다.\n",
        "# dummy_na 인자 : categorical value값이 null인 경우도 칼럼을 생성한다.\n",
        "# drop_first 인자 : categorical value값 중 첫번째 값을 버림\n",
        "data = pd.get_dummies(data, dummy_na=True, drop_first=True)\n",
        "data.drop('Id', axis=1, inplace=True)\n",
        "\n",
        "# any() : 인자로 axis를 가지는데, 디폴트값은 0이다\n",
        "# 마스킹 테이블에 대하여 칼럼별로 False가 값으로 들어있는 테이블을 체크한다. \n",
        "# 만약 인스턴스가 일반 리스트인 경우, 모든 원소에 대해 검사한다. \n",
        "print(data.isnull().values.any())\n",
        "print(data.isnull().any(axis=1))\n",
        "# na값이 상당히 많은 것을 확인할 수 있다. \n",
        "data[data.isnull().any(axis=1)]\n",
        "\n",
        "# 칼럼별로 메디안값을 계산한 series객체를 반환한다. \n",
        "data.median()\n",
        "# 데이터 전처리\n",
        "# fillna 인자로 series객체를 주면, 해당 칼럼에 해당하는 series객체의 값을 넣어준다.\n",
        "data.fillna(data.median(), inplace=True)\n",
        "columns = data.columns\n",
        "data.isnull().values.any()\n",
        "\n",
        "# 데이터 전처리 복구를 위하여 min, max, mean 저장\n",
        "maxSalePrice = data['SalePrice'].max()\n",
        "minSalePrice = data['SalePrice'].min()\n",
        "meanSalePrice = data['SalePrice'].mean()\n",
        "X = data['SalePrice']\n",
        "stdSalePrice = (X - X.min(axis=0)) / (X.max(axis=0) - X.min(axis=0))\n",
        "# X_scaled = X_std * (max - min) + min\n",
        "\n",
        "print(maxSalePrice)\n",
        "print(minSalePrice)\n",
        "print(meanSalePrice)\n",
        "print(stdSalePrice)\n",
        "\n",
        "scaler = MinMaxScaler()\n",
        "# 데이터 정규화\n",
        "data = pd.DataFrame(scaler.fit_transform(data), columns=columns)\n",
        "# 데이터 복원 예시\n",
        "test = pd.DataFrame(scaler.inverse_transform(data), columns=columns)\n",
        "\n",
        "train_data = data.iloc[:1461]\n",
        "test_data = data.iloc[1461:]"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1460, 81)\n",
            "(1459, 80)\n",
            "True\n",
            "0       False\n",
            "1       False\n",
            "2       False\n",
            "3       False\n",
            "4       False\n",
            "        ...  \n",
            "2914     True\n",
            "2915     True\n",
            "2916     True\n",
            "2917     True\n",
            "2918     True\n",
            "Length: 2919, dtype: bool\n",
            "755000.0\n",
            "34900.0\n",
            "171963.6676944159\n",
            "0       0.241078\n",
            "1       0.203583\n",
            "2       0.261908\n",
            "3       0.145952\n",
            "4       0.298709\n",
            "          ...   \n",
            "2914    0.177892\n",
            "2915    0.177892\n",
            "2916    0.177892\n",
            "2917    0.177892\n",
            "2918    0.177892\n",
            "Name: SalePrice, Length: 2919, dtype: float64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rfx0NoqFoRVu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Model(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.fc1 = nn.Linear(288, 144)\n",
        "    self.fc2 = nn.Linear(144, 72)\n",
        "    self.fc3 = nn.Linear(72, 18)\n",
        "    self.fc4 = nn.Linear(18, 1)\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = F.relu(self.fc1(x))\n",
        "    x = F.relu(self.fc2(x))\n",
        "    x = F.relu(self.fc3(x))\n",
        "    x = F.relu(self.fc4(x))\n",
        "    return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MtYnfwU4uE6G",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class houseDataset(Dataset):\n",
        "  def __init__(self, train=True):\n",
        "    if train:\n",
        "      data = train_data.copy()\n",
        "    else:\n",
        "      data = test_data.copy()\n",
        "    self.len = data.shape[0]\n",
        "    self.x_data = torch.from_numpy(data.drop('SalePrice', axis=1).values).float()\n",
        "    self.y_data = torch.from_numpy(data['SalePrice'].values).view(-1,1).float()\n",
        "\n",
        "  def __getitem__(self, index):\n",
        "    return self.x_data[index], self.y_data[index]\n",
        "\n",
        "  def __len__(self):\n",
        "    return self.len\n",
        "\n",
        "dataset = houseDataset(train=True)\n",
        "trainset = houseDataset(train=False)\n",
        "train_loader = DataLoader(dataset=dataset,\n",
        "                          batch_size=32,\n",
        "                          shuffle=True,\n",
        "                          num_workers=2)\n",
        "test_loader = DataLoader(dataset=trainset,\n",
        "                         batch_size=len(trainset),\n",
        "                         num_workers=2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TJC-7km6wJZ0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "fab27a5c-1148-4189-9397-cb04364447cf"
      },
      "source": [
        "model = Model()\n",
        "device = 'cuda' if cuda.is_available() else 'cpu'\n",
        "print(f'Training MNIST Model on {device}\\n{\"=\" * 44}')\n",
        "model.to(device)\n",
        "criterion = nn.MSELoss()\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.001)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training MNIST Model on cpu\n",
            "============================================\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U_yCSPdFwg9Q",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "a6718ffd-f06f-4a74-d960-d0fcd99f1d47"
      },
      "source": [
        "def train(epoch):\n",
        "  model.train()\n",
        "  for batch_idx, (data, target) in enumerate(train_loader):\n",
        "    data, target = data.to(device), target.to(device)\n",
        "    optimizer.zero_grad()\n",
        "    output = model(data)\n",
        "    loss = criterion(output, target)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    if batch_idx % 10 == 0:\n",
        "      print('Train Epoch: {} | Batch Status: {}/{} ({:.0f}%) | Loss: {:.6f}'.format(\n",
        "          epoch, batch_idx*len(data), len(train_loader.dataset),\n",
        "          100. * batch_idx / len(train_loader), loss.item()\n",
        "      ))\n",
        "\n",
        "def test():\n",
        "  model.eval()\n",
        "  with torch.no_grad():\n",
        "    for data, target in test_loader:\n",
        "      data, target = data.to(device), target.to(device)\n",
        "      output = model(data)\n",
        "    result = output*(maxSalePrice-minSalePrice) + minSalePrice\n",
        "    print(result)\n",
        "    plt.plot(result)\n",
        "    plt.show()\n",
        "  \n",
        "since = time.time()\n",
        "for epoch in range(100):\n",
        "    epoch_start = time.time()\n",
        "    train(epoch)\n",
        "    m, s = divmod(time.time() - epoch_start, 60)\n",
        "    print(f'Training time: {m:.0f}m {s:.0f}s')\n",
        "test()\n",
        "\n",
        "m, s = divmod(time.time() - since, 60)\n",
        "print(f'Total Time: {m:.0f}m {s:.0f}s\\nModel was trained on {device}!')"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train Epoch: 0 | Batch Status: 0/1461 (0%) | Loss: 0.007162\n",
            "Train Epoch: 0 | Batch Status: 320/1461 (22%) | Loss: 0.004275\n",
            "Train Epoch: 0 | Batch Status: 640/1461 (43%) | Loss: 0.012006\n",
            "Train Epoch: 0 | Batch Status: 960/1461 (65%) | Loss: 0.007873\n",
            "Train Epoch: 0 | Batch Status: 1280/1461 (87%) | Loss: 0.006103\n",
            "Training time: 0m 0s\n",
            "Train Epoch: 1 | Batch Status: 0/1461 (0%) | Loss: 0.008473\n",
            "Train Epoch: 1 | Batch Status: 320/1461 (22%) | Loss: 0.013878\n",
            "Train Epoch: 1 | Batch Status: 640/1461 (43%) | Loss: 0.006601\n",
            "Train Epoch: 1 | Batch Status: 960/1461 (65%) | Loss: 0.010333\n",
            "Train Epoch: 1 | Batch Status: 1280/1461 (87%) | Loss: 0.008536\n",
            "Training time: 0m 0s\n",
            "Train Epoch: 2 | Batch Status: 0/1461 (0%) | Loss: 0.009824\n",
            "Train Epoch: 2 | Batch Status: 320/1461 (22%) | Loss: 0.006485\n",
            "Train Epoch: 2 | Batch Status: 640/1461 (43%) | Loss: 0.011863\n",
            "Train Epoch: 2 | Batch Status: 960/1461 (65%) | Loss: 0.007484\n",
            "Train Epoch: 2 | Batch Status: 1280/1461 (87%) | Loss: 0.013925\n",
            "Training time: 0m 0s\n",
            "Train Epoch: 3 | Batch Status: 0/1461 (0%) | Loss: 0.008098\n",
            "Train Epoch: 3 | Batch Status: 320/1461 (22%) | Loss: 0.010634\n",
            "Train Epoch: 3 | Batch Status: 640/1461 (43%) | Loss: 0.009844\n",
            "Train Epoch: 3 | Batch Status: 960/1461 (65%) | Loss: 0.028296\n",
            "Train Epoch: 3 | Batch Status: 1280/1461 (87%) | Loss: 0.005418\n",
            "Training time: 0m 0s\n",
            "Train Epoch: 4 | Batch Status: 0/1461 (0%) | Loss: 0.006604\n",
            "Train Epoch: 4 | Batch Status: 320/1461 (22%) | Loss: 0.013850\n",
            "Train Epoch: 4 | Batch Status: 640/1461 (43%) | Loss: 0.005480\n",
            "Train Epoch: 4 | Batch Status: 960/1461 (65%) | Loss: 0.010029\n",
            "Train Epoch: 4 | Batch Status: 1280/1461 (87%) | Loss: 0.008682\n",
            "Training time: 0m 0s\n",
            "Train Epoch: 5 | Batch Status: 0/1461 (0%) | Loss: 0.006108\n",
            "Train Epoch: 5 | Batch Status: 320/1461 (22%) | Loss: 0.006345\n",
            "Train Epoch: 5 | Batch Status: 640/1461 (43%) | Loss: 0.007878\n",
            "Train Epoch: 5 | Batch Status: 960/1461 (65%) | Loss: 0.006134\n",
            "Train Epoch: 5 | Batch Status: 1280/1461 (87%) | Loss: 0.016321\n",
            "Training time: 0m 0s\n",
            "Train Epoch: 6 | Batch Status: 0/1461 (0%) | Loss: 0.013923\n",
            "Train Epoch: 6 | Batch Status: 320/1461 (22%) | Loss: 0.005775\n",
            "Train Epoch: 6 | Batch Status: 640/1461 (43%) | Loss: 0.011793\n",
            "Train Epoch: 6 | Batch Status: 960/1461 (65%) | Loss: 0.006740\n",
            "Train Epoch: 6 | Batch Status: 1280/1461 (87%) | Loss: 0.004655\n",
            "Training time: 0m 0s\n",
            "Train Epoch: 7 | Batch Status: 0/1461 (0%) | Loss: 0.004697\n",
            "Train Epoch: 7 | Batch Status: 320/1461 (22%) | Loss: 0.010467\n",
            "Train Epoch: 7 | Batch Status: 640/1461 (43%) | Loss: 0.007009\n",
            "Train Epoch: 7 | Batch Status: 960/1461 (65%) | Loss: 0.033301\n",
            "Train Epoch: 7 | Batch Status: 1280/1461 (87%) | Loss: 0.013838\n",
            "Training time: 0m 0s\n",
            "Train Epoch: 8 | Batch Status: 0/1461 (0%) | Loss: 0.008078\n",
            "Train Epoch: 8 | Batch Status: 320/1461 (22%) | Loss: 0.014925\n",
            "Train Epoch: 8 | Batch Status: 640/1461 (43%) | Loss: 0.006596\n",
            "Train Epoch: 8 | Batch Status: 960/1461 (65%) | Loss: 0.019743\n",
            "Train Epoch: 8 | Batch Status: 1280/1461 (87%) | Loss: 0.014203\n",
            "Training time: 0m 0s\n",
            "Train Epoch: 9 | Batch Status: 0/1461 (0%) | Loss: 0.011360\n",
            "Train Epoch: 9 | Batch Status: 320/1461 (22%) | Loss: 0.007237\n",
            "Train Epoch: 9 | Batch Status: 640/1461 (43%) | Loss: 0.006654\n",
            "Train Epoch: 9 | Batch Status: 960/1461 (65%) | Loss: 0.007305\n",
            "Train Epoch: 9 | Batch Status: 1280/1461 (87%) | Loss: 0.008999\n",
            "Training time: 0m 0s\n",
            "Train Epoch: 10 | Batch Status: 0/1461 (0%) | Loss: 0.009045\n",
            "Train Epoch: 10 | Batch Status: 320/1461 (22%) | Loss: 0.033710\n",
            "Train Epoch: 10 | Batch Status: 640/1461 (43%) | Loss: 0.006439\n",
            "Train Epoch: 10 | Batch Status: 960/1461 (65%) | Loss: 0.006793\n",
            "Train Epoch: 10 | Batch Status: 1280/1461 (87%) | Loss: 0.015064\n",
            "Training time: 0m 0s\n",
            "Train Epoch: 11 | Batch Status: 0/1461 (0%) | Loss: 0.012885\n",
            "Train Epoch: 11 | Batch Status: 320/1461 (22%) | Loss: 0.005998\n",
            "Train Epoch: 11 | Batch Status: 640/1461 (43%) | Loss: 0.006281\n",
            "Train Epoch: 11 | Batch Status: 960/1461 (65%) | Loss: 0.007000\n",
            "Train Epoch: 11 | Batch Status: 1280/1461 (87%) | Loss: 0.002988\n",
            "Training time: 0m 0s\n",
            "Train Epoch: 12 | Batch Status: 0/1461 (0%) | Loss: 0.008658\n",
            "Train Epoch: 12 | Batch Status: 320/1461 (22%) | Loss: 0.005111\n",
            "Train Epoch: 12 | Batch Status: 640/1461 (43%) | Loss: 0.018742\n",
            "Train Epoch: 12 | Batch Status: 960/1461 (65%) | Loss: 0.006683\n",
            "Train Epoch: 12 | Batch Status: 1280/1461 (87%) | Loss: 0.007344\n",
            "Training time: 0m 0s\n",
            "Train Epoch: 13 | Batch Status: 0/1461 (0%) | Loss: 0.007800\n",
            "Train Epoch: 13 | Batch Status: 320/1461 (22%) | Loss: 0.006327\n",
            "Train Epoch: 13 | Batch Status: 640/1461 (43%) | Loss: 0.008621\n",
            "Train Epoch: 13 | Batch Status: 960/1461 (65%) | Loss: 0.011066\n",
            "Train Epoch: 13 | Batch Status: 1280/1461 (87%) | Loss: 0.014613\n",
            "Training time: 0m 0s\n",
            "Train Epoch: 14 | Batch Status: 0/1461 (0%) | Loss: 0.007311\n",
            "Train Epoch: 14 | Batch Status: 320/1461 (22%) | Loss: 0.005019\n",
            "Train Epoch: 14 | Batch Status: 640/1461 (43%) | Loss: 0.007402\n",
            "Train Epoch: 14 | Batch Status: 960/1461 (65%) | Loss: 0.009457\n",
            "Train Epoch: 14 | Batch Status: 1280/1461 (87%) | Loss: 0.007293\n",
            "Training time: 0m 0s\n",
            "Train Epoch: 15 | Batch Status: 0/1461 (0%) | Loss: 0.006718\n",
            "Train Epoch: 15 | Batch Status: 320/1461 (22%) | Loss: 0.011703\n",
            "Train Epoch: 15 | Batch Status: 640/1461 (43%) | Loss: 0.006601\n",
            "Train Epoch: 15 | Batch Status: 960/1461 (65%) | Loss: 0.012878\n",
            "Train Epoch: 15 | Batch Status: 1280/1461 (87%) | Loss: 0.020667\n",
            "Training time: 0m 0s\n",
            "Train Epoch: 16 | Batch Status: 0/1461 (0%) | Loss: 0.009991\n",
            "Train Epoch: 16 | Batch Status: 320/1461 (22%) | Loss: 0.007556\n",
            "Train Epoch: 16 | Batch Status: 640/1461 (43%) | Loss: 0.010368\n",
            "Train Epoch: 16 | Batch Status: 960/1461 (65%) | Loss: 0.006832\n",
            "Train Epoch: 16 | Batch Status: 1280/1461 (87%) | Loss: 0.005849\n",
            "Training time: 0m 0s\n",
            "Train Epoch: 17 | Batch Status: 0/1461 (0%) | Loss: 0.010339\n",
            "Train Epoch: 17 | Batch Status: 320/1461 (22%) | Loss: 0.010179\n",
            "Train Epoch: 17 | Batch Status: 640/1461 (43%) | Loss: 0.008507\n",
            "Train Epoch: 17 | Batch Status: 960/1461 (65%) | Loss: 0.006675\n",
            "Train Epoch: 17 | Batch Status: 1280/1461 (87%) | Loss: 0.012858\n",
            "Training time: 0m 0s\n",
            "Train Epoch: 18 | Batch Status: 0/1461 (0%) | Loss: 0.008997\n",
            "Train Epoch: 18 | Batch Status: 320/1461 (22%) | Loss: 0.007845\n",
            "Train Epoch: 18 | Batch Status: 640/1461 (43%) | Loss: 0.005099\n",
            "Train Epoch: 18 | Batch Status: 960/1461 (65%) | Loss: 0.005321\n",
            "Train Epoch: 18 | Batch Status: 1280/1461 (87%) | Loss: 0.003373\n",
            "Training time: 0m 0s\n",
            "Train Epoch: 19 | Batch Status: 0/1461 (0%) | Loss: 0.006147\n",
            "Train Epoch: 19 | Batch Status: 320/1461 (22%) | Loss: 0.012653\n",
            "Train Epoch: 19 | Batch Status: 640/1461 (43%) | Loss: 0.010271\n",
            "Train Epoch: 19 | Batch Status: 960/1461 (65%) | Loss: 0.017725\n",
            "Train Epoch: 19 | Batch Status: 1280/1461 (87%) | Loss: 0.007344\n",
            "Training time: 0m 0s\n",
            "Train Epoch: 20 | Batch Status: 0/1461 (0%) | Loss: 0.014635\n",
            "Train Epoch: 20 | Batch Status: 320/1461 (22%) | Loss: 0.008770\n",
            "Train Epoch: 20 | Batch Status: 640/1461 (43%) | Loss: 0.005903\n",
            "Train Epoch: 20 | Batch Status: 960/1461 (65%) | Loss: 0.016501\n",
            "Train Epoch: 20 | Batch Status: 1280/1461 (87%) | Loss: 0.008369\n",
            "Training time: 0m 0s\n",
            "Train Epoch: 21 | Batch Status: 0/1461 (0%) | Loss: 0.011429\n",
            "Train Epoch: 21 | Batch Status: 320/1461 (22%) | Loss: 0.008021\n",
            "Train Epoch: 21 | Batch Status: 640/1461 (43%) | Loss: 0.008242\n",
            "Train Epoch: 21 | Batch Status: 960/1461 (65%) | Loss: 0.006908\n",
            "Train Epoch: 21 | Batch Status: 1280/1461 (87%) | Loss: 0.006222\n",
            "Training time: 0m 0s\n",
            "Train Epoch: 22 | Batch Status: 0/1461 (0%) | Loss: 0.006745\n",
            "Train Epoch: 22 | Batch Status: 320/1461 (22%) | Loss: 0.013361\n",
            "Train Epoch: 22 | Batch Status: 640/1461 (43%) | Loss: 0.007221\n",
            "Train Epoch: 22 | Batch Status: 960/1461 (65%) | Loss: 0.007764\n",
            "Train Epoch: 22 | Batch Status: 1280/1461 (87%) | Loss: 0.007632\n",
            "Training time: 0m 0s\n",
            "Train Epoch: 23 | Batch Status: 0/1461 (0%) | Loss: 0.011995\n",
            "Train Epoch: 23 | Batch Status: 320/1461 (22%) | Loss: 0.016342\n",
            "Train Epoch: 23 | Batch Status: 640/1461 (43%) | Loss: 0.011683\n",
            "Train Epoch: 23 | Batch Status: 960/1461 (65%) | Loss: 0.004917\n",
            "Train Epoch: 23 | Batch Status: 1280/1461 (87%) | Loss: 0.009340\n",
            "Training time: 0m 0s\n",
            "Train Epoch: 24 | Batch Status: 0/1461 (0%) | Loss: 0.009738\n",
            "Train Epoch: 24 | Batch Status: 320/1461 (22%) | Loss: 0.005010\n",
            "Train Epoch: 24 | Batch Status: 640/1461 (43%) | Loss: 0.014488\n",
            "Train Epoch: 24 | Batch Status: 960/1461 (65%) | Loss: 0.007336\n",
            "Train Epoch: 24 | Batch Status: 1280/1461 (87%) | Loss: 0.007017\n",
            "Training time: 0m 0s\n",
            "Train Epoch: 25 | Batch Status: 0/1461 (0%) | Loss: 0.008214\n",
            "Train Epoch: 25 | Batch Status: 320/1461 (22%) | Loss: 0.009024\n",
            "Train Epoch: 25 | Batch Status: 640/1461 (43%) | Loss: 0.005839\n",
            "Train Epoch: 25 | Batch Status: 960/1461 (65%) | Loss: 0.011449\n",
            "Train Epoch: 25 | Batch Status: 1280/1461 (87%) | Loss: 0.006038\n",
            "Training time: 0m 0s\n",
            "Train Epoch: 26 | Batch Status: 0/1461 (0%) | Loss: 0.017237\n",
            "Train Epoch: 26 | Batch Status: 320/1461 (22%) | Loss: 0.007484\n",
            "Train Epoch: 26 | Batch Status: 640/1461 (43%) | Loss: 0.005567\n",
            "Train Epoch: 26 | Batch Status: 960/1461 (65%) | Loss: 0.005970\n",
            "Train Epoch: 26 | Batch Status: 1280/1461 (87%) | Loss: 0.014614\n",
            "Training time: 0m 0s\n",
            "Train Epoch: 27 | Batch Status: 0/1461 (0%) | Loss: 0.011529\n",
            "Train Epoch: 27 | Batch Status: 320/1461 (22%) | Loss: 0.004752\n",
            "Train Epoch: 27 | Batch Status: 640/1461 (43%) | Loss: 0.007140\n",
            "Train Epoch: 27 | Batch Status: 960/1461 (65%) | Loss: 0.006684\n",
            "Train Epoch: 27 | Batch Status: 1280/1461 (87%) | Loss: 0.012987\n",
            "Training time: 0m 0s\n",
            "Train Epoch: 28 | Batch Status: 0/1461 (0%) | Loss: 0.008372\n",
            "Train Epoch: 28 | Batch Status: 320/1461 (22%) | Loss: 0.014040\n",
            "Train Epoch: 28 | Batch Status: 640/1461 (43%) | Loss: 0.013336\n",
            "Train Epoch: 28 | Batch Status: 960/1461 (65%) | Loss: 0.009276\n",
            "Train Epoch: 28 | Batch Status: 1280/1461 (87%) | Loss: 0.005521\n",
            "Training time: 0m 0s\n",
            "Train Epoch: 29 | Batch Status: 0/1461 (0%) | Loss: 0.005357\n",
            "Train Epoch: 29 | Batch Status: 320/1461 (22%) | Loss: 0.003434\n",
            "Train Epoch: 29 | Batch Status: 640/1461 (43%) | Loss: 0.005946\n",
            "Train Epoch: 29 | Batch Status: 960/1461 (65%) | Loss: 0.009836\n",
            "Train Epoch: 29 | Batch Status: 1280/1461 (87%) | Loss: 0.004393\n",
            "Training time: 0m 0s\n",
            "Train Epoch: 30 | Batch Status: 0/1461 (0%) | Loss: 0.010373\n",
            "Train Epoch: 30 | Batch Status: 320/1461 (22%) | Loss: 0.006516\n",
            "Train Epoch: 30 | Batch Status: 640/1461 (43%) | Loss: 0.008058\n",
            "Train Epoch: 30 | Batch Status: 960/1461 (65%) | Loss: 0.005223\n",
            "Train Epoch: 30 | Batch Status: 1280/1461 (87%) | Loss: 0.008012\n",
            "Training time: 0m 0s\n",
            "Train Epoch: 31 | Batch Status: 0/1461 (0%) | Loss: 0.010576\n",
            "Train Epoch: 31 | Batch Status: 320/1461 (22%) | Loss: 0.005367\n",
            "Train Epoch: 31 | Batch Status: 640/1461 (43%) | Loss: 0.012470\n",
            "Train Epoch: 31 | Batch Status: 960/1461 (65%) | Loss: 0.010190\n",
            "Train Epoch: 31 | Batch Status: 1280/1461 (87%) | Loss: 0.026768\n",
            "Training time: 0m 0s\n",
            "Train Epoch: 32 | Batch Status: 0/1461 (0%) | Loss: 0.006726\n",
            "Train Epoch: 32 | Batch Status: 320/1461 (22%) | Loss: 0.014335\n",
            "Train Epoch: 32 | Batch Status: 640/1461 (43%) | Loss: 0.015005\n",
            "Train Epoch: 32 | Batch Status: 960/1461 (65%) | Loss: 0.013631\n",
            "Train Epoch: 32 | Batch Status: 1280/1461 (87%) | Loss: 0.013754\n",
            "Training time: 0m 0s\n",
            "Train Epoch: 33 | Batch Status: 0/1461 (0%) | Loss: 0.014262\n",
            "Train Epoch: 33 | Batch Status: 320/1461 (22%) | Loss: 0.005536\n",
            "Train Epoch: 33 | Batch Status: 640/1461 (43%) | Loss: 0.011069\n",
            "Train Epoch: 33 | Batch Status: 960/1461 (65%) | Loss: 0.023136\n",
            "Train Epoch: 33 | Batch Status: 1280/1461 (87%) | Loss: 0.008662\n",
            "Training time: 0m 0s\n",
            "Train Epoch: 34 | Batch Status: 0/1461 (0%) | Loss: 0.010170\n",
            "Train Epoch: 34 | Batch Status: 320/1461 (22%) | Loss: 0.016146\n",
            "Train Epoch: 34 | Batch Status: 640/1461 (43%) | Loss: 0.010800\n",
            "Train Epoch: 34 | Batch Status: 960/1461 (65%) | Loss: 0.007255\n",
            "Train Epoch: 34 | Batch Status: 1280/1461 (87%) | Loss: 0.008043\n",
            "Training time: 0m 0s\n",
            "Train Epoch: 35 | Batch Status: 0/1461 (0%) | Loss: 0.012933\n",
            "Train Epoch: 35 | Batch Status: 320/1461 (22%) | Loss: 0.026335\n",
            "Train Epoch: 35 | Batch Status: 640/1461 (43%) | Loss: 0.006943\n",
            "Train Epoch: 35 | Batch Status: 960/1461 (65%) | Loss: 0.025591\n",
            "Train Epoch: 35 | Batch Status: 1280/1461 (87%) | Loss: 0.004780\n",
            "Training time: 0m 0s\n",
            "Train Epoch: 36 | Batch Status: 0/1461 (0%) | Loss: 0.007566\n",
            "Train Epoch: 36 | Batch Status: 320/1461 (22%) | Loss: 0.005037\n",
            "Train Epoch: 36 | Batch Status: 640/1461 (43%) | Loss: 0.005818\n",
            "Train Epoch: 36 | Batch Status: 960/1461 (65%) | Loss: 0.009730\n",
            "Train Epoch: 36 | Batch Status: 1280/1461 (87%) | Loss: 0.012803\n",
            "Training time: 0m 0s\n",
            "Train Epoch: 37 | Batch Status: 0/1461 (0%) | Loss: 0.006346\n",
            "Train Epoch: 37 | Batch Status: 320/1461 (22%) | Loss: 0.008534\n",
            "Train Epoch: 37 | Batch Status: 640/1461 (43%) | Loss: 0.007949\n",
            "Train Epoch: 37 | Batch Status: 960/1461 (65%) | Loss: 0.022089\n",
            "Train Epoch: 37 | Batch Status: 1280/1461 (87%) | Loss: 0.005887\n",
            "Training time: 0m 0s\n",
            "Train Epoch: 38 | Batch Status: 0/1461 (0%) | Loss: 0.015072\n",
            "Train Epoch: 38 | Batch Status: 320/1461 (22%) | Loss: 0.006073\n",
            "Train Epoch: 38 | Batch Status: 640/1461 (43%) | Loss: 0.015217\n",
            "Train Epoch: 38 | Batch Status: 960/1461 (65%) | Loss: 0.004264\n",
            "Train Epoch: 38 | Batch Status: 1280/1461 (87%) | Loss: 0.008066\n",
            "Training time: 0m 0s\n",
            "Train Epoch: 39 | Batch Status: 0/1461 (0%) | Loss: 0.018202\n",
            "Train Epoch: 39 | Batch Status: 320/1461 (22%) | Loss: 0.005891\n",
            "Train Epoch: 39 | Batch Status: 640/1461 (43%) | Loss: 0.004212\n",
            "Train Epoch: 39 | Batch Status: 960/1461 (65%) | Loss: 0.014911\n",
            "Train Epoch: 39 | Batch Status: 1280/1461 (87%) | Loss: 0.009296\n",
            "Training time: 0m 0s\n",
            "Train Epoch: 40 | Batch Status: 0/1461 (0%) | Loss: 0.008112\n",
            "Train Epoch: 40 | Batch Status: 320/1461 (22%) | Loss: 0.019387\n",
            "Train Epoch: 40 | Batch Status: 640/1461 (43%) | Loss: 0.009286\n",
            "Train Epoch: 40 | Batch Status: 960/1461 (65%) | Loss: 0.009830\n",
            "Train Epoch: 40 | Batch Status: 1280/1461 (87%) | Loss: 0.009623\n",
            "Training time: 0m 0s\n",
            "Train Epoch: 41 | Batch Status: 0/1461 (0%) | Loss: 0.004413\n",
            "Train Epoch: 41 | Batch Status: 320/1461 (22%) | Loss: 0.012804\n",
            "Train Epoch: 41 | Batch Status: 640/1461 (43%) | Loss: 0.010121\n",
            "Train Epoch: 41 | Batch Status: 960/1461 (65%) | Loss: 0.005722\n",
            "Train Epoch: 41 | Batch Status: 1280/1461 (87%) | Loss: 0.012475\n",
            "Training time: 0m 0s\n",
            "Train Epoch: 42 | Batch Status: 0/1461 (0%) | Loss: 0.019553\n",
            "Train Epoch: 42 | Batch Status: 320/1461 (22%) | Loss: 0.011026\n",
            "Train Epoch: 42 | Batch Status: 640/1461 (43%) | Loss: 0.003714\n",
            "Train Epoch: 42 | Batch Status: 960/1461 (65%) | Loss: 0.006660\n",
            "Train Epoch: 42 | Batch Status: 1280/1461 (87%) | Loss: 0.007702\n",
            "Training time: 0m 0s\n",
            "Train Epoch: 43 | Batch Status: 0/1461 (0%) | Loss: 0.011777\n",
            "Train Epoch: 43 | Batch Status: 320/1461 (22%) | Loss: 0.004865\n",
            "Train Epoch: 43 | Batch Status: 640/1461 (43%) | Loss: 0.013097\n",
            "Train Epoch: 43 | Batch Status: 960/1461 (65%) | Loss: 0.011611\n",
            "Train Epoch: 43 | Batch Status: 1280/1461 (87%) | Loss: 0.029026\n",
            "Training time: 0m 0s\n",
            "Train Epoch: 44 | Batch Status: 0/1461 (0%) | Loss: 0.007106\n",
            "Train Epoch: 44 | Batch Status: 320/1461 (22%) | Loss: 0.013553\n",
            "Train Epoch: 44 | Batch Status: 640/1461 (43%) | Loss: 0.003930\n",
            "Train Epoch: 44 | Batch Status: 960/1461 (65%) | Loss: 0.009735\n",
            "Train Epoch: 44 | Batch Status: 1280/1461 (87%) | Loss: 0.008575\n",
            "Training time: 0m 0s\n",
            "Train Epoch: 45 | Batch Status: 0/1461 (0%) | Loss: 0.010635\n",
            "Train Epoch: 45 | Batch Status: 320/1461 (22%) | Loss: 0.004741\n",
            "Train Epoch: 45 | Batch Status: 640/1461 (43%) | Loss: 0.010954\n",
            "Train Epoch: 45 | Batch Status: 960/1461 (65%) | Loss: 0.013555\n",
            "Train Epoch: 45 | Batch Status: 1280/1461 (87%) | Loss: 0.008676\n",
            "Training time: 0m 0s\n",
            "Train Epoch: 46 | Batch Status: 0/1461 (0%) | Loss: 0.028956\n",
            "Train Epoch: 46 | Batch Status: 320/1461 (22%) | Loss: 0.007296\n",
            "Train Epoch: 46 | Batch Status: 640/1461 (43%) | Loss: 0.007532\n",
            "Train Epoch: 46 | Batch Status: 960/1461 (65%) | Loss: 0.025973\n",
            "Train Epoch: 46 | Batch Status: 1280/1461 (87%) | Loss: 0.010495\n",
            "Training time: 0m 0s\n",
            "Train Epoch: 47 | Batch Status: 0/1461 (0%) | Loss: 0.021901\n",
            "Train Epoch: 47 | Batch Status: 320/1461 (22%) | Loss: 0.005617\n",
            "Train Epoch: 47 | Batch Status: 640/1461 (43%) | Loss: 0.007785\n",
            "Train Epoch: 47 | Batch Status: 960/1461 (65%) | Loss: 0.010021\n",
            "Train Epoch: 47 | Batch Status: 1280/1461 (87%) | Loss: 0.008353\n",
            "Training time: 0m 0s\n",
            "Train Epoch: 48 | Batch Status: 0/1461 (0%) | Loss: 0.005965\n",
            "Train Epoch: 48 | Batch Status: 320/1461 (22%) | Loss: 0.008941\n",
            "Train Epoch: 48 | Batch Status: 640/1461 (43%) | Loss: 0.006079\n",
            "Train Epoch: 48 | Batch Status: 960/1461 (65%) | Loss: 0.010565\n",
            "Train Epoch: 48 | Batch Status: 1280/1461 (87%) | Loss: 0.006151\n",
            "Training time: 0m 0s\n",
            "Train Epoch: 49 | Batch Status: 0/1461 (0%) | Loss: 0.013837\n",
            "Train Epoch: 49 | Batch Status: 320/1461 (22%) | Loss: 0.023557\n",
            "Train Epoch: 49 | Batch Status: 640/1461 (43%) | Loss: 0.011412\n",
            "Train Epoch: 49 | Batch Status: 960/1461 (65%) | Loss: 0.008664\n",
            "Train Epoch: 49 | Batch Status: 1280/1461 (87%) | Loss: 0.005902\n",
            "Training time: 0m 0s\n",
            "Train Epoch: 50 | Batch Status: 0/1461 (0%) | Loss: 0.012730\n",
            "Train Epoch: 50 | Batch Status: 320/1461 (22%) | Loss: 0.019952\n",
            "Train Epoch: 50 | Batch Status: 640/1461 (43%) | Loss: 0.015750\n",
            "Train Epoch: 50 | Batch Status: 960/1461 (65%) | Loss: 0.009834\n",
            "Train Epoch: 50 | Batch Status: 1280/1461 (87%) | Loss: 0.007557\n",
            "Training time: 0m 0s\n",
            "Train Epoch: 51 | Batch Status: 0/1461 (0%) | Loss: 0.006739\n",
            "Train Epoch: 51 | Batch Status: 320/1461 (22%) | Loss: 0.016961\n",
            "Train Epoch: 51 | Batch Status: 640/1461 (43%) | Loss: 0.014280\n",
            "Train Epoch: 51 | Batch Status: 960/1461 (65%) | Loss: 0.006540\n",
            "Train Epoch: 51 | Batch Status: 1280/1461 (87%) | Loss: 0.022423\n",
            "Training time: 0m 0s\n",
            "Train Epoch: 52 | Batch Status: 0/1461 (0%) | Loss: 0.011093\n",
            "Train Epoch: 52 | Batch Status: 320/1461 (22%) | Loss: 0.009540\n",
            "Train Epoch: 52 | Batch Status: 640/1461 (43%) | Loss: 0.006200\n",
            "Train Epoch: 52 | Batch Status: 960/1461 (65%) | Loss: 0.019520\n",
            "Train Epoch: 52 | Batch Status: 1280/1461 (87%) | Loss: 0.007838\n",
            "Training time: 0m 0s\n",
            "Train Epoch: 53 | Batch Status: 0/1461 (0%) | Loss: 0.005850\n",
            "Train Epoch: 53 | Batch Status: 320/1461 (22%) | Loss: 0.003834\n",
            "Train Epoch: 53 | Batch Status: 640/1461 (43%) | Loss: 0.028439\n",
            "Train Epoch: 53 | Batch Status: 960/1461 (65%) | Loss: 0.010601\n",
            "Train Epoch: 53 | Batch Status: 1280/1461 (87%) | Loss: 0.005723\n",
            "Training time: 0m 0s\n",
            "Train Epoch: 54 | Batch Status: 0/1461 (0%) | Loss: 0.010757\n",
            "Train Epoch: 54 | Batch Status: 320/1461 (22%) | Loss: 0.009574\n",
            "Train Epoch: 54 | Batch Status: 640/1461 (43%) | Loss: 0.006502\n",
            "Train Epoch: 54 | Batch Status: 960/1461 (65%) | Loss: 0.023430\n",
            "Train Epoch: 54 | Batch Status: 1280/1461 (87%) | Loss: 0.015649\n",
            "Training time: 0m 0s\n",
            "Train Epoch: 55 | Batch Status: 0/1461 (0%) | Loss: 0.008372\n",
            "Train Epoch: 55 | Batch Status: 320/1461 (22%) | Loss: 0.017587\n",
            "Train Epoch: 55 | Batch Status: 640/1461 (43%) | Loss: 0.005352\n",
            "Train Epoch: 55 | Batch Status: 960/1461 (65%) | Loss: 0.007920\n",
            "Train Epoch: 55 | Batch Status: 1280/1461 (87%) | Loss: 0.005156\n",
            "Training time: 0m 0s\n",
            "Train Epoch: 56 | Batch Status: 0/1461 (0%) | Loss: 0.013813\n",
            "Train Epoch: 56 | Batch Status: 320/1461 (22%) | Loss: 0.012495\n",
            "Train Epoch: 56 | Batch Status: 640/1461 (43%) | Loss: 0.010648\n",
            "Train Epoch: 56 | Batch Status: 960/1461 (65%) | Loss: 0.005165\n",
            "Train Epoch: 56 | Batch Status: 1280/1461 (87%) | Loss: 0.005386\n",
            "Training time: 0m 0s\n",
            "Train Epoch: 57 | Batch Status: 0/1461 (0%) | Loss: 0.003701\n",
            "Train Epoch: 57 | Batch Status: 320/1461 (22%) | Loss: 0.006242\n",
            "Train Epoch: 57 | Batch Status: 640/1461 (43%) | Loss: 0.011461\n",
            "Train Epoch: 57 | Batch Status: 960/1461 (65%) | Loss: 0.009328\n",
            "Train Epoch: 57 | Batch Status: 1280/1461 (87%) | Loss: 0.005308\n",
            "Training time: 0m 0s\n",
            "Train Epoch: 58 | Batch Status: 0/1461 (0%) | Loss: 0.004426\n",
            "Train Epoch: 58 | Batch Status: 320/1461 (22%) | Loss: 0.014651\n",
            "Train Epoch: 58 | Batch Status: 640/1461 (43%) | Loss: 0.012399\n",
            "Train Epoch: 58 | Batch Status: 960/1461 (65%) | Loss: 0.014139\n",
            "Train Epoch: 58 | Batch Status: 1280/1461 (87%) | Loss: 0.005849\n",
            "Training time: 0m 0s\n",
            "Train Epoch: 59 | Batch Status: 0/1461 (0%) | Loss: 0.009623\n",
            "Train Epoch: 59 | Batch Status: 320/1461 (22%) | Loss: 0.012529\n",
            "Train Epoch: 59 | Batch Status: 640/1461 (43%) | Loss: 0.009588\n",
            "Train Epoch: 59 | Batch Status: 960/1461 (65%) | Loss: 0.009087\n",
            "Train Epoch: 59 | Batch Status: 1280/1461 (87%) | Loss: 0.017889\n",
            "Training time: 0m 0s\n",
            "Train Epoch: 60 | Batch Status: 0/1461 (0%) | Loss: 0.014585\n",
            "Train Epoch: 60 | Batch Status: 320/1461 (22%) | Loss: 0.013554\n",
            "Train Epoch: 60 | Batch Status: 640/1461 (43%) | Loss: 0.007409\n",
            "Train Epoch: 60 | Batch Status: 960/1461 (65%) | Loss: 0.019780\n",
            "Train Epoch: 60 | Batch Status: 1280/1461 (87%) | Loss: 0.009516\n",
            "Training time: 0m 0s\n",
            "Train Epoch: 61 | Batch Status: 0/1461 (0%) | Loss: 0.009320\n",
            "Train Epoch: 61 | Batch Status: 320/1461 (22%) | Loss: 0.011051\n",
            "Train Epoch: 61 | Batch Status: 640/1461 (43%) | Loss: 0.008153\n",
            "Train Epoch: 61 | Batch Status: 960/1461 (65%) | Loss: 0.005166\n",
            "Train Epoch: 61 | Batch Status: 1280/1461 (87%) | Loss: 0.004378\n",
            "Training time: 0m 0s\n",
            "Train Epoch: 62 | Batch Status: 0/1461 (0%) | Loss: 0.008638\n",
            "Train Epoch: 62 | Batch Status: 320/1461 (22%) | Loss: 0.003879\n",
            "Train Epoch: 62 | Batch Status: 640/1461 (43%) | Loss: 0.014879\n",
            "Train Epoch: 62 | Batch Status: 960/1461 (65%) | Loss: 0.030183\n",
            "Train Epoch: 62 | Batch Status: 1280/1461 (87%) | Loss: 0.006322\n",
            "Training time: 0m 0s\n",
            "Train Epoch: 63 | Batch Status: 0/1461 (0%) | Loss: 0.006114\n",
            "Train Epoch: 63 | Batch Status: 320/1461 (22%) | Loss: 0.011150\n",
            "Train Epoch: 63 | Batch Status: 640/1461 (43%) | Loss: 0.019053\n",
            "Train Epoch: 63 | Batch Status: 960/1461 (65%) | Loss: 0.022812\n",
            "Train Epoch: 63 | Batch Status: 1280/1461 (87%) | Loss: 0.007135\n",
            "Training time: 0m 0s\n",
            "Train Epoch: 64 | Batch Status: 0/1461 (0%) | Loss: 0.010330\n",
            "Train Epoch: 64 | Batch Status: 320/1461 (22%) | Loss: 0.012393\n",
            "Train Epoch: 64 | Batch Status: 640/1461 (43%) | Loss: 0.007868\n",
            "Train Epoch: 64 | Batch Status: 960/1461 (65%) | Loss: 0.004491\n",
            "Train Epoch: 64 | Batch Status: 1280/1461 (87%) | Loss: 0.012237\n",
            "Training time: 0m 0s\n",
            "Train Epoch: 65 | Batch Status: 0/1461 (0%) | Loss: 0.007726\n",
            "Train Epoch: 65 | Batch Status: 320/1461 (22%) | Loss: 0.004704\n",
            "Train Epoch: 65 | Batch Status: 640/1461 (43%) | Loss: 0.009220\n",
            "Train Epoch: 65 | Batch Status: 960/1461 (65%) | Loss: 0.006612\n",
            "Train Epoch: 65 | Batch Status: 1280/1461 (87%) | Loss: 0.038590\n",
            "Training time: 0m 0s\n",
            "Train Epoch: 66 | Batch Status: 0/1461 (0%) | Loss: 0.005482\n",
            "Train Epoch: 66 | Batch Status: 320/1461 (22%) | Loss: 0.011579\n",
            "Train Epoch: 66 | Batch Status: 640/1461 (43%) | Loss: 0.010953\n",
            "Train Epoch: 66 | Batch Status: 960/1461 (65%) | Loss: 0.019533\n",
            "Train Epoch: 66 | Batch Status: 1280/1461 (87%) | Loss: 0.007845\n",
            "Training time: 0m 0s\n",
            "Train Epoch: 67 | Batch Status: 0/1461 (0%) | Loss: 0.010917\n",
            "Train Epoch: 67 | Batch Status: 320/1461 (22%) | Loss: 0.014218\n",
            "Train Epoch: 67 | Batch Status: 640/1461 (43%) | Loss: 0.008530\n",
            "Train Epoch: 67 | Batch Status: 960/1461 (65%) | Loss: 0.009403\n",
            "Train Epoch: 67 | Batch Status: 1280/1461 (87%) | Loss: 0.007737\n",
            "Training time: 0m 0s\n",
            "Train Epoch: 68 | Batch Status: 0/1461 (0%) | Loss: 0.010538\n",
            "Train Epoch: 68 | Batch Status: 320/1461 (22%) | Loss: 0.027676\n",
            "Train Epoch: 68 | Batch Status: 640/1461 (43%) | Loss: 0.011429\n",
            "Train Epoch: 68 | Batch Status: 960/1461 (65%) | Loss: 0.028179\n",
            "Train Epoch: 68 | Batch Status: 1280/1461 (87%) | Loss: 0.005278\n",
            "Training time: 0m 0s\n",
            "Train Epoch: 69 | Batch Status: 0/1461 (0%) | Loss: 0.010287\n",
            "Train Epoch: 69 | Batch Status: 320/1461 (22%) | Loss: 0.012522\n",
            "Train Epoch: 69 | Batch Status: 640/1461 (43%) | Loss: 0.014743\n",
            "Train Epoch: 69 | Batch Status: 960/1461 (65%) | Loss: 0.008567\n",
            "Train Epoch: 69 | Batch Status: 1280/1461 (87%) | Loss: 0.008267\n",
            "Training time: 0m 0s\n",
            "Train Epoch: 70 | Batch Status: 0/1461 (0%) | Loss: 0.005211\n",
            "Train Epoch: 70 | Batch Status: 320/1461 (22%) | Loss: 0.005149\n",
            "Train Epoch: 70 | Batch Status: 640/1461 (43%) | Loss: 0.006330\n",
            "Train Epoch: 70 | Batch Status: 960/1461 (65%) | Loss: 0.011867\n",
            "Train Epoch: 70 | Batch Status: 1280/1461 (87%) | Loss: 0.004181\n",
            "Training time: 0m 0s\n",
            "Train Epoch: 71 | Batch Status: 0/1461 (0%) | Loss: 0.012494\n",
            "Train Epoch: 71 | Batch Status: 320/1461 (22%) | Loss: 0.009209\n",
            "Train Epoch: 71 | Batch Status: 640/1461 (43%) | Loss: 0.009868\n",
            "Train Epoch: 71 | Batch Status: 960/1461 (65%) | Loss: 0.008930\n",
            "Train Epoch: 71 | Batch Status: 1280/1461 (87%) | Loss: 0.013933\n",
            "Training time: 0m 0s\n",
            "Train Epoch: 72 | Batch Status: 0/1461 (0%) | Loss: 0.006111\n",
            "Train Epoch: 72 | Batch Status: 320/1461 (22%) | Loss: 0.012012\n",
            "Train Epoch: 72 | Batch Status: 640/1461 (43%) | Loss: 0.005729\n",
            "Train Epoch: 72 | Batch Status: 960/1461 (65%) | Loss: 0.012957\n",
            "Train Epoch: 72 | Batch Status: 1280/1461 (87%) | Loss: 0.011891\n",
            "Training time: 0m 0s\n",
            "Train Epoch: 73 | Batch Status: 0/1461 (0%) | Loss: 0.008556\n",
            "Train Epoch: 73 | Batch Status: 320/1461 (22%) | Loss: 0.017695\n",
            "Train Epoch: 73 | Batch Status: 640/1461 (43%) | Loss: 0.013679\n",
            "Train Epoch: 73 | Batch Status: 960/1461 (65%) | Loss: 0.010135\n",
            "Train Epoch: 73 | Batch Status: 1280/1461 (87%) | Loss: 0.005042\n",
            "Training time: 0m 0s\n",
            "Train Epoch: 74 | Batch Status: 0/1461 (0%) | Loss: 0.009802\n",
            "Train Epoch: 74 | Batch Status: 320/1461 (22%) | Loss: 0.004527\n",
            "Train Epoch: 74 | Batch Status: 640/1461 (43%) | Loss: 0.005408\n",
            "Train Epoch: 74 | Batch Status: 960/1461 (65%) | Loss: 0.007321\n",
            "Train Epoch: 74 | Batch Status: 1280/1461 (87%) | Loss: 0.012696\n",
            "Training time: 0m 0s\n",
            "Train Epoch: 75 | Batch Status: 0/1461 (0%) | Loss: 0.006818\n",
            "Train Epoch: 75 | Batch Status: 320/1461 (22%) | Loss: 0.004978\n",
            "Train Epoch: 75 | Batch Status: 640/1461 (43%) | Loss: 0.011279\n",
            "Train Epoch: 75 | Batch Status: 960/1461 (65%) | Loss: 0.004366\n",
            "Train Epoch: 75 | Batch Status: 1280/1461 (87%) | Loss: 0.014073\n",
            "Training time: 0m 0s\n",
            "Train Epoch: 76 | Batch Status: 0/1461 (0%) | Loss: 0.005879\n",
            "Train Epoch: 76 | Batch Status: 320/1461 (22%) | Loss: 0.014973\n",
            "Train Epoch: 76 | Batch Status: 640/1461 (43%) | Loss: 0.010900\n",
            "Train Epoch: 76 | Batch Status: 960/1461 (65%) | Loss: 0.008212\n",
            "Train Epoch: 76 | Batch Status: 1280/1461 (87%) | Loss: 0.006743\n",
            "Training time: 0m 0s\n",
            "Train Epoch: 77 | Batch Status: 0/1461 (0%) | Loss: 0.004334\n",
            "Train Epoch: 77 | Batch Status: 320/1461 (22%) | Loss: 0.008904\n",
            "Train Epoch: 77 | Batch Status: 640/1461 (43%) | Loss: 0.018317\n",
            "Train Epoch: 77 | Batch Status: 960/1461 (65%) | Loss: 0.011801\n",
            "Train Epoch: 77 | Batch Status: 1280/1461 (87%) | Loss: 0.004063\n",
            "Training time: 0m 0s\n",
            "Train Epoch: 78 | Batch Status: 0/1461 (0%) | Loss: 0.006125\n",
            "Train Epoch: 78 | Batch Status: 320/1461 (22%) | Loss: 0.026778\n",
            "Train Epoch: 78 | Batch Status: 640/1461 (43%) | Loss: 0.010510\n",
            "Train Epoch: 78 | Batch Status: 960/1461 (65%) | Loss: 0.008071\n",
            "Train Epoch: 78 | Batch Status: 1280/1461 (87%) | Loss: 0.005984\n",
            "Training time: 0m 0s\n",
            "Train Epoch: 79 | Batch Status: 0/1461 (0%) | Loss: 0.005485\n",
            "Train Epoch: 79 | Batch Status: 320/1461 (22%) | Loss: 0.007484\n",
            "Train Epoch: 79 | Batch Status: 640/1461 (43%) | Loss: 0.005192\n",
            "Train Epoch: 79 | Batch Status: 960/1461 (65%) | Loss: 0.009142\n",
            "Train Epoch: 79 | Batch Status: 1280/1461 (87%) | Loss: 0.017073\n",
            "Training time: 0m 0s\n",
            "Train Epoch: 80 | Batch Status: 0/1461 (0%) | Loss: 0.005280\n",
            "Train Epoch: 80 | Batch Status: 320/1461 (22%) | Loss: 0.006147\n",
            "Train Epoch: 80 | Batch Status: 640/1461 (43%) | Loss: 0.004879\n",
            "Train Epoch: 80 | Batch Status: 960/1461 (65%) | Loss: 0.015933\n",
            "Train Epoch: 80 | Batch Status: 1280/1461 (87%) | Loss: 0.008184\n",
            "Training time: 0m 0s\n",
            "Train Epoch: 81 | Batch Status: 0/1461 (0%) | Loss: 0.004865\n",
            "Train Epoch: 81 | Batch Status: 320/1461 (22%) | Loss: 0.006335\n",
            "Train Epoch: 81 | Batch Status: 640/1461 (43%) | Loss: 0.015813\n",
            "Train Epoch: 81 | Batch Status: 960/1461 (65%) | Loss: 0.007032\n",
            "Train Epoch: 81 | Batch Status: 1280/1461 (87%) | Loss: 0.011607\n",
            "Training time: 0m 0s\n",
            "Train Epoch: 82 | Batch Status: 0/1461 (0%) | Loss: 0.014854\n",
            "Train Epoch: 82 | Batch Status: 320/1461 (22%) | Loss: 0.006461\n",
            "Train Epoch: 82 | Batch Status: 640/1461 (43%) | Loss: 0.007062\n",
            "Train Epoch: 82 | Batch Status: 960/1461 (65%) | Loss: 0.010463\n",
            "Train Epoch: 82 | Batch Status: 1280/1461 (87%) | Loss: 0.025271\n",
            "Training time: 0m 0s\n",
            "Train Epoch: 83 | Batch Status: 0/1461 (0%) | Loss: 0.011039\n",
            "Train Epoch: 83 | Batch Status: 320/1461 (22%) | Loss: 0.008633\n",
            "Train Epoch: 83 | Batch Status: 640/1461 (43%) | Loss: 0.020208\n",
            "Train Epoch: 83 | Batch Status: 960/1461 (65%) | Loss: 0.011273\n",
            "Train Epoch: 83 | Batch Status: 1280/1461 (87%) | Loss: 0.011467\n",
            "Training time: 0m 0s\n",
            "Train Epoch: 84 | Batch Status: 0/1461 (0%) | Loss: 0.009854\n",
            "Train Epoch: 84 | Batch Status: 320/1461 (22%) | Loss: 0.025262\n",
            "Train Epoch: 84 | Batch Status: 640/1461 (43%) | Loss: 0.016177\n",
            "Train Epoch: 84 | Batch Status: 960/1461 (65%) | Loss: 0.007090\n",
            "Train Epoch: 84 | Batch Status: 1280/1461 (87%) | Loss: 0.008810\n",
            "Training time: 0m 0s\n",
            "Train Epoch: 85 | Batch Status: 0/1461 (0%) | Loss: 0.005954\n",
            "Train Epoch: 85 | Batch Status: 320/1461 (22%) | Loss: 0.003421\n",
            "Train Epoch: 85 | Batch Status: 640/1461 (43%) | Loss: 0.016176\n",
            "Train Epoch: 85 | Batch Status: 960/1461 (65%) | Loss: 0.006921\n",
            "Train Epoch: 85 | Batch Status: 1280/1461 (87%) | Loss: 0.003161\n",
            "Training time: 0m 0s\n",
            "Train Epoch: 86 | Batch Status: 0/1461 (0%) | Loss: 0.003869\n",
            "Train Epoch: 86 | Batch Status: 320/1461 (22%) | Loss: 0.007466\n",
            "Train Epoch: 86 | Batch Status: 640/1461 (43%) | Loss: 0.016980\n",
            "Train Epoch: 86 | Batch Status: 960/1461 (65%) | Loss: 0.020382\n",
            "Train Epoch: 86 | Batch Status: 1280/1461 (87%) | Loss: 0.007367\n",
            "Training time: 0m 0s\n",
            "Train Epoch: 87 | Batch Status: 0/1461 (0%) | Loss: 0.008717\n",
            "Train Epoch: 87 | Batch Status: 320/1461 (22%) | Loss: 0.004647\n",
            "Train Epoch: 87 | Batch Status: 640/1461 (43%) | Loss: 0.008234\n",
            "Train Epoch: 87 | Batch Status: 960/1461 (65%) | Loss: 0.010526\n",
            "Train Epoch: 87 | Batch Status: 1280/1461 (87%) | Loss: 0.005750\n",
            "Training time: 0m 0s\n",
            "Train Epoch: 88 | Batch Status: 0/1461 (0%) | Loss: 0.010165\n",
            "Train Epoch: 88 | Batch Status: 320/1461 (22%) | Loss: 0.008974\n",
            "Train Epoch: 88 | Batch Status: 640/1461 (43%) | Loss: 0.014390\n",
            "Train Epoch: 88 | Batch Status: 960/1461 (65%) | Loss: 0.004606\n",
            "Train Epoch: 88 | Batch Status: 1280/1461 (87%) | Loss: 0.005006\n",
            "Training time: 0m 0s\n",
            "Train Epoch: 89 | Batch Status: 0/1461 (0%) | Loss: 0.007041\n",
            "Train Epoch: 89 | Batch Status: 320/1461 (22%) | Loss: 0.007835\n",
            "Train Epoch: 89 | Batch Status: 640/1461 (43%) | Loss: 0.019033\n",
            "Train Epoch: 89 | Batch Status: 960/1461 (65%) | Loss: 0.027217\n",
            "Train Epoch: 89 | Batch Status: 1280/1461 (87%) | Loss: 0.005529\n",
            "Training time: 0m 0s\n",
            "Train Epoch: 90 | Batch Status: 0/1461 (0%) | Loss: 0.007428\n",
            "Train Epoch: 90 | Batch Status: 320/1461 (22%) | Loss: 0.019101\n",
            "Train Epoch: 90 | Batch Status: 640/1461 (43%) | Loss: 0.006684\n",
            "Train Epoch: 90 | Batch Status: 960/1461 (65%) | Loss: 0.007916\n",
            "Train Epoch: 90 | Batch Status: 1280/1461 (87%) | Loss: 0.011337\n",
            "Training time: 0m 0s\n",
            "Train Epoch: 91 | Batch Status: 0/1461 (0%) | Loss: 0.007176\n",
            "Train Epoch: 91 | Batch Status: 320/1461 (22%) | Loss: 0.010415\n",
            "Train Epoch: 91 | Batch Status: 640/1461 (43%) | Loss: 0.015434\n",
            "Train Epoch: 91 | Batch Status: 960/1461 (65%) | Loss: 0.005399\n",
            "Train Epoch: 91 | Batch Status: 1280/1461 (87%) | Loss: 0.003878\n",
            "Training time: 0m 0s\n",
            "Train Epoch: 92 | Batch Status: 0/1461 (0%) | Loss: 0.003736\n",
            "Train Epoch: 92 | Batch Status: 320/1461 (22%) | Loss: 0.003758\n",
            "Train Epoch: 92 | Batch Status: 640/1461 (43%) | Loss: 0.006792\n",
            "Train Epoch: 92 | Batch Status: 960/1461 (65%) | Loss: 0.007484\n",
            "Train Epoch: 92 | Batch Status: 1280/1461 (87%) | Loss: 0.009872\n",
            "Training time: 0m 0s\n",
            "Train Epoch: 93 | Batch Status: 0/1461 (0%) | Loss: 0.007780\n",
            "Train Epoch: 93 | Batch Status: 320/1461 (22%) | Loss: 0.012777\n",
            "Train Epoch: 93 | Batch Status: 640/1461 (43%) | Loss: 0.015490\n",
            "Train Epoch: 93 | Batch Status: 960/1461 (65%) | Loss: 0.011986\n",
            "Train Epoch: 93 | Batch Status: 1280/1461 (87%) | Loss: 0.006431\n",
            "Training time: 0m 0s\n",
            "Train Epoch: 94 | Batch Status: 0/1461 (0%) | Loss: 0.007171\n",
            "Train Epoch: 94 | Batch Status: 320/1461 (22%) | Loss: 0.025807\n",
            "Train Epoch: 94 | Batch Status: 640/1461 (43%) | Loss: 0.006569\n",
            "Train Epoch: 94 | Batch Status: 960/1461 (65%) | Loss: 0.013595\n",
            "Train Epoch: 94 | Batch Status: 1280/1461 (87%) | Loss: 0.006944\n",
            "Training time: 0m 0s\n",
            "Train Epoch: 95 | Batch Status: 0/1461 (0%) | Loss: 0.009037\n",
            "Train Epoch: 95 | Batch Status: 320/1461 (22%) | Loss: 0.007579\n",
            "Train Epoch: 95 | Batch Status: 640/1461 (43%) | Loss: 0.008428\n",
            "Train Epoch: 95 | Batch Status: 960/1461 (65%) | Loss: 0.005611\n",
            "Train Epoch: 95 | Batch Status: 1280/1461 (87%) | Loss: 0.012060\n",
            "Training time: 0m 0s\n",
            "Train Epoch: 96 | Batch Status: 0/1461 (0%) | Loss: 0.008303\n",
            "Train Epoch: 96 | Batch Status: 320/1461 (22%) | Loss: 0.007635\n",
            "Train Epoch: 96 | Batch Status: 640/1461 (43%) | Loss: 0.010503\n",
            "Train Epoch: 96 | Batch Status: 960/1461 (65%) | Loss: 0.008058\n",
            "Train Epoch: 96 | Batch Status: 1280/1461 (87%) | Loss: 0.021501\n",
            "Training time: 0m 0s\n",
            "Train Epoch: 97 | Batch Status: 0/1461 (0%) | Loss: 0.016740\n",
            "Train Epoch: 97 | Batch Status: 320/1461 (22%) | Loss: 0.010089\n",
            "Train Epoch: 97 | Batch Status: 640/1461 (43%) | Loss: 0.008385\n",
            "Train Epoch: 97 | Batch Status: 960/1461 (65%) | Loss: 0.006567\n",
            "Train Epoch: 97 | Batch Status: 1280/1461 (87%) | Loss: 0.007360\n",
            "Training time: 0m 0s\n",
            "Train Epoch: 98 | Batch Status: 0/1461 (0%) | Loss: 0.007064\n",
            "Train Epoch: 98 | Batch Status: 320/1461 (22%) | Loss: 0.004200\n",
            "Train Epoch: 98 | Batch Status: 640/1461 (43%) | Loss: 0.009044\n",
            "Train Epoch: 98 | Batch Status: 960/1461 (65%) | Loss: 0.009618\n",
            "Train Epoch: 98 | Batch Status: 1280/1461 (87%) | Loss: 0.003725\n",
            "Training time: 0m 0s\n",
            "Train Epoch: 99 | Batch Status: 0/1461 (0%) | Loss: 0.010329\n",
            "Train Epoch: 99 | Batch Status: 320/1461 (22%) | Loss: 0.005785\n",
            "Train Epoch: 99 | Batch Status: 640/1461 (43%) | Loss: 0.014612\n",
            "Train Epoch: 99 | Batch Status: 960/1461 (65%) | Loss: 0.011203\n",
            "Train Epoch: 99 | Batch Status: 1280/1461 (87%) | Loss: 0.007527\n",
            "Training time: 0m 0s\n",
            "tensor([[180042.9844],\n",
            "        [187538.3750],\n",
            "        [190544.4062],\n",
            "        ...,\n",
            "        [177897.4375],\n",
            "        [168683.7656],\n",
            "        [185972.8906]])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Total Time: 0m 19s\n",
            "Model was trained on cpu!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s6whBm7BbKX6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}